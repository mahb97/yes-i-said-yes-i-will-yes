{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkrJo/sjK9mR0V4jE33T70",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahb97/yes-i-said-yes-i-will-yes/blob/main/corpus_extraction_pass1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This notebook performs the first pass of corpus extraction, flagging candidate passages for manual annotation. Accounts for free indirect discourse, mediated speech, and complex attribution challenges in Joyce's text.*"
      ],
      "metadata": {
        "id": "5Lub3I4LWFcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Notebook overview and summary\n",
        "\n",
        "print(\"\"\"\n",
        "           ♥♥♥♥♥♥♥           ♥♥♥♥♥♥♥\n",
        "         ♥♥♥♥♥♥♥♥♥♥♥       ♥♥♥♥♥♥♥♥♥♥♥\n",
        "       ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥   ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "      ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥ ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "     ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "     ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "     ♥  MOLLY BLOOM CANDIDATE EXTRACTION  ♥\n",
        "     ♥                                    ♥\n",
        "     ♥      yes-i-said-yes-i-will-yes     ♥\n",
        "     ♥                                    ♥\n",
        "      ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "       ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "         ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "           ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "             ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "               ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "                 ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
        "                   ♥♥♥♥♥♥♥♥♥♥♥\n",
        "                     ♥♥♥♥♥♥♥\n",
        "                       ♥♥♥\n",
        "                        ♥\n",
        "\n",
        "PROJECT GOAL:\n",
        "Training a language model on Molly Bloom's voice from Joyce's Ulysses to\n",
        "center female-coded language and stream-of-consciousness as primary rather\n",
        "than peripheral.\n",
        "\n",
        "THIS NOTEBOOK:\n",
        "First pass corpus extraction using rule-based NLP to identify candidate\n",
        "passages for manual annotation.\n",
        "\n",
        "PIPELINE STAGES:\n",
        "\n",
        "1. Setup & Dependencies\n",
        "   - Load required libraries\n",
        "   - Define data structures and enumerations\n",
        "\n",
        "2. Text Loading\n",
        "   - Upload cleaned Ulysses text\n",
        "   - Verify file integrity\n",
        "\n",
        "3. Pattern Initialization\n",
        "   - Define regex patterns for:\n",
        "     * Mediation markers (male-encoded speech)\n",
        "     * Direct speech indicators\n",
        "     * Molly-specific vocabulary\n",
        "     * Female embodiment language\n",
        "\n",
        "4. Episode Identification\n",
        "   - Locate Penelope episode (definite Molly text)\n",
        "   - Mark episode boundaries for context\n",
        "\n",
        "5. Mediation Detection\n",
        "   - Check for Bloom's memories vs. direct speech\n",
        "   - Flag male-encoded passages for exclusion\n",
        "   - Calculate Molly-likelihood scores\n",
        "\n",
        "6. Candidate Extraction\n",
        "   - Extract Penelope (100% confidence)\n",
        "   - Find dialogue candidates throughout text\n",
        "   - Apply automatic classification\n",
        "\n",
        "7. Sample Review\n",
        "   - Display samples from each confidence level\n",
        "   - Inspect automatic flagging quality\n",
        "\n",
        "8. Report Generation\n",
        "   - Create structured markdown annotation file\n",
        "   - Include context, reasoning, and flags\n",
        "   - Organize by confidence level\n",
        "\n",
        "9. Download & Manual Annotation\n",
        "   - Download generated markdown file\n",
        "   - Begin manual review process\n",
        "\n",
        "CRITICAL PRINCIPLE:\n",
        "Bloom's memory of Molly's words ≠ Molly's words\n",
        "\n",
        "Even direct quotes filtered through male recollection are encoded in male\n",
        "language. This is the computational equivalent of the male gaze. We exclude\n",
        "all male-mediated passages to preserve primary female voice.\n",
        "\n",
        "EXPECTED OUTPUT:\n",
        "A markdown file containing:\n",
        "- Penelope episode (definite inclusion)\n",
        "- ~100 dialogue candidates with confidence scores\n",
        "- Context windows for each passage\n",
        "- Automatic flags and reasoning\n",
        "- Space for manual annotation decisions\n",
        "\n",
        "NEXT STEPS AFTER THIS NOTEBOOK:\n",
        "1. Manual annotation of candidate passages\n",
        "2. Create stage-specific corpus files\n",
        "3. Implement overlap-cluster melting for Stage 3\n",
        "4. Begin three-stage training pipeline\n",
        "\n",
        "════════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "Ready to begin extraction.\n",
        "For Molly.\n",
        "\n",
        "════════════════════════════════════════════════════════════════════════════\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nNotebook cells:\")\n",
        "print(\"Cell 1:  This overview\")\n",
        "print(\"Cell 2:  Dependencies and imports\")\n",
        "print(\"Cell 3:  Data structure definitions\")\n",
        "print(\"Cell 4:  File upload and text loading\")\n",
        "print(\"Cell 5:  MollyCandidateFinder class initialization\")\n",
        "print(\"Cell 6:  Helper methods (context, episodes)\")\n",
        "print(\"Cell 7:  Mediation detection methods\")\n",
        "print(\"Cell 8:  Penelope extraction\")\n",
        "print(\"Cell 9:  Dialogue candidate extraction\")\n",
        "print(\"Cell 10: Sample candidate review\")\n",
        "print(\"Cell 11: Markdown generation functions (header)\")\n",
        "print(\"Cell 12: Markdown generation functions (sections)\")\n",
        "print(\"Cell 13: Complete report generation\")\n",
        "print(\"Cell 14: Download annotation file\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Run cells sequentially from Cell 2 onwards.\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6euMS-DId_pJ",
        "outputId": "b364d035-bf99-4a6f-a159-38fbecc840f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "           ♥♥♥♥♥♥♥           ♥♥♥♥♥♥♥\n",
            "         ♥♥♥♥♥♥♥♥♥♥♥       ♥♥♥♥♥♥♥♥♥♥♥\n",
            "       ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥   ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "      ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥ ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "     ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "     ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "     ♥  MOLLY BLOOM CANDIDATE EXTRACTION  ♥\n",
            "     ♥                                    ♥\n",
            "     ♥      yes-i-said-yes-i-will-yes     ♥\n",
            "     ♥                                    ♥\n",
            "      ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "       ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "         ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "           ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "             ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "               ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "                 ♥♥♥♥♥♥♥♥♥♥♥♥♥♥♥\n",
            "                   ♥♥♥♥♥♥♥♥♥♥♥\n",
            "                     ♥♥♥♥♥♥♥\n",
            "                       ♥♥♥\n",
            "                        ♥\n",
            "\n",
            "PROJECT GOAL:\n",
            "Training a language model on Molly Bloom's voice from Joyce's Ulysses to \n",
            "center female-coded language and stream-of-consciousness as primary rather \n",
            "than peripheral.\n",
            "\n",
            "THIS NOTEBOOK:\n",
            "First pass corpus extraction using rule-based NLP to identify candidate \n",
            "passages for manual annotation.\n",
            "\n",
            "PIPELINE STAGES:\n",
            "\n",
            "1. Setup & Dependencies\n",
            "   - Load required libraries\n",
            "   - Define data structures and enumerations\n",
            "\n",
            "2. Text Loading\n",
            "   - Upload cleaned Ulysses text\n",
            "   - Verify file integrity\n",
            "\n",
            "3. Pattern Initialization\n",
            "   - Define regex patterns for:\n",
            "     * Mediation markers (male-encoded speech)\n",
            "     * Direct speech indicators\n",
            "     * Molly-specific vocabulary\n",
            "     * Female embodiment language\n",
            "\n",
            "4. Episode Identification\n",
            "   - Locate Penelope episode (definite Molly text)\n",
            "   - Mark episode boundaries for context\n",
            "\n",
            "5. Mediation Detection\n",
            "   - Check for Bloom's memories vs. direct speech\n",
            "   - Flag male-encoded passages for exclusion\n",
            "   - Calculate Molly-likelihood scores\n",
            "\n",
            "6. Candidate Extraction\n",
            "   - Extract Penelope (100% confidence)\n",
            "   - Find dialogue candidates throughout text\n",
            "   - Apply automatic classification\n",
            "\n",
            "7. Sample Review\n",
            "   - Display samples from each confidence level\n",
            "   - Inspect automatic flagging quality\n",
            "\n",
            "8. Report Generation\n",
            "   - Create structured markdown annotation file\n",
            "   - Include context, reasoning, and flags\n",
            "   - Organize by confidence level\n",
            "\n",
            "9. Download & Manual Annotation\n",
            "   - Download generated markdown file\n",
            "   - Begin manual review process\n",
            "\n",
            "CRITICAL PRINCIPLE:\n",
            "Bloom's memory of Molly's words ≠ Molly's words\n",
            "\n",
            "Even direct quotes filtered through male recollection are encoded in male \n",
            "language. This is the computational equivalent of the male gaze. We exclude\n",
            "all male-mediated passages to preserve primary female voice.\n",
            "\n",
            "EXPECTED OUTPUT:\n",
            "A markdown file containing:\n",
            "- Penelope episode (definite inclusion)\n",
            "- ~100 dialogue candidates with confidence scores\n",
            "- Context windows for each passage\n",
            "- Automatic flags and reasoning\n",
            "- Space for manual annotation decisions\n",
            "\n",
            "NEXT STEPS AFTER THIS NOTEBOOK:\n",
            "1. Manual annotation of candidate passages\n",
            "2. Create stage-specific corpus files\n",
            "3. Implement overlap-cluster melting for Stage 3\n",
            "4. Begin three-stage training pipeline\n",
            "\n",
            "════════════════════════════════════════════════════════════════════════════\n",
            "\n",
            "Ready to begin extraction.\n",
            "For Molly.\n",
            "\n",
            "════════════════════════════════════════════════════════════════════════════\n",
            "\n",
            "\n",
            "Notebook cells:\n",
            "Cell 1:  This overview\n",
            "Cell 2:  Dependencies and imports\n",
            "Cell 3:  Data structure definitions\n",
            "Cell 4:  File upload and text loading\n",
            "Cell 5:  MollyCandidateFinder class initialization\n",
            "Cell 6:  Helper methods (context, episodes)\n",
            "Cell 7:  Mediation detection methods\n",
            "Cell 8:  Penelope extraction\n",
            "Cell 9:  Dialogue candidate extraction\n",
            "Cell 10: Sample candidate review\n",
            "Cell 11: Markdown generation functions (header)\n",
            "Cell 12: Markdown generation functions (sections)\n",
            "Cell 13: Complete report generation\n",
            "Cell 14: Download annotation file\n",
            "\n",
            "============================================================\n",
            "Run cells sequentially from Cell 2 onwards.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw4fAxcGvrPV",
        "outputId": "183b7f4f-9fcb-4b8f-ade6-b0fa416c9e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies loaded successfully.\n",
            "Python environment ready for Molly Bloom extraction.\n"
          ]
        }
      ],
      "source": [
        "# Molly Bloom Candidate Extraction System - Setup\n",
        "\n",
        "import re\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# lib for text processing\n",
        "import unicodedata\n",
        "from IPython.display import display, Markdown, HTML\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data structures and enumerations\n",
        "# classification for candidate passages\n",
        "\n",
        "class PassageType(Enum):\n",
        "    \"\"\"Classification of passage types for annotation.\"\"\"\n",
        "    DIRECT_DIALOGUE = \"direct_dialogue\"\n",
        "    INTERIOR_MONOLOGUE = \"interior_monologue\"\n",
        "    THEATRICAL = \"theatrical\"\n",
        "    MEDIATED_MEMORY = \"mediated_memory\"\n",
        "    AMBIGUOUS = \"ambiguous\"\n",
        "\n",
        "\n",
        "class ConfidenceLevel(Enum):\n",
        "    \"\"\"Confidence levels for automatic classification.\"\"\"\n",
        "    DEFINITE = \"definite\"\n",
        "    PROBABLE = \"probable\"\n",
        "    REQUIRES_REVIEW = \"requires_review\"\n",
        "    EXCLUDE = \"exclude\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PassageCandidate:\n",
        "    \"\"\"\n",
        "    Data structure for a candidate Molly Bloom passage.\n",
        "\n",
        "    Attributes:\n",
        "        text: The passage text\n",
        "        location: Character offset in source text\n",
        "        episode: Episode name if available\n",
        "        passage_type: Automatic classification of passage type\n",
        "        confidence: Confidence level for this classification\n",
        "        context_before: Preceding text for disambiguation\n",
        "        context_after: Following text for disambiguation\n",
        "        flags: List of automatic detection flags\n",
        "        reasoning: Explanation for classification\n",
        "    \"\"\"\n",
        "    text: str\n",
        "    location: int\n",
        "    episode: Optional[str]\n",
        "    passage_type: PassageType\n",
        "    confidence: ConfidenceLevel\n",
        "    context_before: str\n",
        "    context_after: str\n",
        "    flags: List[str]\n",
        "    reasoning: str\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"PassageCandidate(location={self.location}, confidence={self.confidence.value}, type={self.passage_type.value})\"\n",
        "\n",
        "print(f\"Available passage types: {[pt.value for pt in PassageType]}\")\n",
        "print(f\"Available confidence levels: {[cl.value for cl in ConfidenceLevel]}\")"
      ],
      "metadata": {
        "id": "WJNSuUK6WNkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files and text loading (pre-clean txt manually)\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ulysses.txt\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "ulysses_text = uploaded[filename].decode('utf-8')\n",
        "\n",
        "# statistics\n",
        "char_count = len(ulysses_text)\n",
        "word_count = len(ulysses_text.split())\n",
        "line_count = ulysses_text.count('\\n')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"Filename: {filename}\")\n",
        "print(f\"Characters: {char_count:,}\")\n",
        "print(f\"Words (approximate): {word_count:,}\")\n",
        "print(f\"Lines: {line_count:,}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# first 500 chars as sanity check\n",
        "print(\"\\nFirst 500 characters:\")\n",
        "print(\"-\" * 60)\n",
        "print(ulysses_text[:500])\n",
        "print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "22jj9Eo_WjfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MollyCandidateFinder Class - Initialization and Pattern Definitions (core class for identifying potential passages)\n",
        "\n",
        "class MollyCandidateFinder:\n",
        "    \"\"\"\n",
        "    Rule-based system for identifying candidate Molly Bloom passages.\n",
        "\n",
        "    This system does not attempt full automatic extraction, but rather\n",
        "    flags passages that require human judgment. Inspired by challenges\n",
        "    encountered in rule-based approaches to Dubliners stylistic analysis.\n",
        "\n",
        "    Parameters:\n",
        "        ulysses_text: Full text of Ulysses\n",
        "        context_window: Characters of context to extract (default: 200)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ulysses_text: str, context_window: int = 200):\n",
        "        self.text = ulysses_text\n",
        "        self.context_window = context_window\n",
        "        self.episodes = {}  # add\n",
        "\n",
        "        # pattern definitions\n",
        "        self.patterns = self._initialize_patterns()\n",
        "\n",
        "        print(f\"MollyCandidateFinder initialized.\")\n",
        "        print(f\"Text length: {len(self.text):,} characters\")\n",
        "        print(f\"Context window: {self.context_window} characters\")\n",
        "        print(f\"Pattern categories loaded: {list(self.patterns.keys())}\")\n",
        "\n",
        "    def _initialize_patterns(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"\n",
        "        Initialize regex patterns for passage identification.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping pattern categories to regex lists\n",
        "        \"\"\"\n",
        "        patterns = {\n",
        "            'mediation_markers': [\n",
        "                r'he remembered.*?(?:Molly|she) (?:said|saying)',\n",
        "                r'(?:Molly|she) had said',\n",
        "                r'(?:Molly|she) told him',\n",
        "                r'he recalled.*?her words?',\n",
        "                r'(?:she|Molly) would say',\n",
        "                r'(?:she|Molly) might say',\n",
        "                r'(?:she|Molly) used to say',\n",
        "                r'he thought of.*?(?:her|Molly)',\n",
        "                r'remembered.*?(?:her|Molly).*?voice',\n",
        "                r'imagined.*?(?:her|Molly)',\n",
        "            ],\n",
        "            'direct_speech': [\n",
        "                r'—\\s*[A-Z]',  # Em dash\n",
        "                r'\"[^\"]+\"\\s*(?:she says?|Molly says?)',\n",
        "                r':\\s*—',  # Colon / dialogue dash\n",
        "            ],\n",
        "            'molly_vocabulary': [\n",
        "                # vocab\n",
        "                r'\\bGibraltar\\b',\n",
        "                r'\\bMulvey\\b',\n",
        "                r'\\bBoylan\\b',\n",
        "                r'\\bHester\\b',\n",
        "                r'\\bpoldy\\b',\n",
        "                # to be extended (yo i need to do another manual pass on ulysses give me a minute)\n",
        "            ],\n",
        "            'female_embodiment': [\n",
        "                # vocab\n",
        "                r'\\bbreast',\n",
        "                r'\\bmenstr',\n",
        "                r'\\bpregnan',\n",
        "                r'\\bwomb\\b',\n",
        "                r'\\bflesh\\b',\n",
        "                r'\\bbody\\b',\n",
        "            ],\n",
        "            'domestic_vocabulary': [\n",
        "                r'\\bbed\\b',\n",
        "                r'\\bsheet',\n",
        "                r'\\bpillow',\n",
        "                r'\\bwashing\\b',\n",
        "                r'\\bcooking\\b',\n",
        "                r'\\bkitchen\\b',\n",
        "            ],\n",
        "        }\n",
        "\n",
        "        return patterns\n",
        "\n",
        "\n",
        "# use finder\n",
        "finder = MollyCandidateFinder(ulysses_text)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"Mediation markers: {len(finder.patterns['mediation_markers'])} patterns\")\n",
        "print(f\"Direct speech markers: {len(finder.patterns['direct_speech'])} patterns\")\n",
        "print(f\"Molly vocabulary markers: {len(finder.patterns['molly_vocabulary'])} patterns\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "-3YrA16qXhhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helpers - context extraction and episode identification\n",
        "\n",
        "def get_context(self, position: int) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Extract context before and after a given position.\n",
        "\n",
        "    Parameters:\n",
        "        position: Character position in text\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (context_before, context_after)\n",
        "    \"\"\"\n",
        "    start = max(0, position - self.context_window)\n",
        "    end = min(len(self.text), position + self.context_window)\n",
        "\n",
        "    context_before = self.text[start:position]\n",
        "    context_after = self.text[position:end]\n",
        "\n",
        "    return context_before, context_after\n",
        "\n",
        "\n",
        "def identify_episode_boundaries(self) -> Dict[str, Tuple[int, int]]:\n",
        "    \"\"\"\n",
        "    Identify episode boundaries in Ulysses text.\n",
        "\n",
        "    Penelope is the most critical episode for this project.\n",
        "    Uses known starting phrase to locate it.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping episode names to (start, end) character positions\n",
        "    \"\"\"\n",
        "    episodes = {}\n",
        "\n",
        "    # start phrase\n",
        "    penelope_starts = [\n",
        "        \"Yes because he never did a thing like that before\",\n",
        "        \"Yes because he never did\",\n",
        "    ]\n",
        "\n",
        "    for phrase in penelope_starts:\n",
        "        penelope_start = self.text.rfind(phrase)\n",
        "        if penelope_start != -1:\n",
        "            episodes['Penelope'] = (penelope_start, len(self.text))\n",
        "            print(f\"Penelope episode located at position {penelope_start:,}\")\n",
        "            break\n",
        "\n",
        "    if 'Penelope' not in episodes:\n",
        "        print(\"WARNING: Penelope episode not automatically located.\")\n",
        "        print(\"Manual identification may be required.\")\n",
        "\n",
        "    # to be extended\n",
        "\n",
        "    return episodes\n",
        "\n",
        "\n",
        "def get_episode_name(self, position: int) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Determine which episode a position falls within.\n",
        "\n",
        "    Parameters:\n",
        "        position: Character position in text\n",
        "\n",
        "    Returns:\n",
        "        Episode name or None if not found\n",
        "    \"\"\"\n",
        "    for episode, (start, end) in self.episodes.items():\n",
        "        if start <= position < end:\n",
        "            return episode\n",
        "    return None\n",
        "\n",
        "\n",
        "# methods for finder class\n",
        "MollyCandidateFinder.get_context = get_context\n",
        "MollyCandidateFinder.identify_episode_boundaries = identify_episode_boundaries\n",
        "MollyCandidateFinder.get_episode_name = get_episode_name\n",
        "\n",
        "# find episodes\n",
        "finder.episodes = finder.identify_episode_boundaries()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Episode identification complete.\")\n",
        "print(f\"Episodes found: {list(finder.episodes.keys())}\")\n",
        "if 'Penelope' in finder.episodes:\n",
        "    start, end = finder.episodes['Penelope']\n",
        "    length = end - start\n",
        "    print(f\"Penelope length: {length:,} characters (~{length//5:,} words)\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "9WGFZazjYPje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mediation Detection Methods (critical methods for identifying male-encoded speech vs. primary Molly voice)\n",
        "\n",
        "def check_mediation(self, passage: str, context: str) -> Tuple[bool, List[str]]:\n",
        "    \"\"\"\n",
        "    Check if passage contains markers of male-encoded mediation.\n",
        "\n",
        "    Critical: Bloom's memory of Molly's words is encoded in male language.\n",
        "    Even direct quotes filtered through his recollection are not primary sources.\n",
        "    This is the computational equivalent of the male gaze for language.\n",
        "\n",
        "    Parameters:\n",
        "        passage: The text to check\n",
        "        context: Surrounding context\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (is_mediated, list of matched patterns)\n",
        "    \"\"\"\n",
        "    matched_patterns = []\n",
        "    combined_text = context + \" \" + passage\n",
        "\n",
        "    for pattern in self.patterns['mediation_markers']:\n",
        "        if re.search(pattern, combined_text, re.IGNORECASE):\n",
        "            matched_patterns.append(pattern)\n",
        "\n",
        "    return len(matched_patterns) > 0, matched_patterns\n",
        "\n",
        "\n",
        "def check_direct_speech(self, passage: str) -> Tuple[bool, List[str]]:\n",
        "    \"\"\"\n",
        "    Check if passage contains markers of direct, real-time speech.\n",
        "\n",
        "    Direct speech is unmediated - Molly speaking in the present moment\n",
        "    of the narrative, not filtered through memory or imagination.\n",
        "\n",
        "    Parameters:\n",
        "        passage: The text to check\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (is_direct, list of matched patterns)\n",
        "    \"\"\"\n",
        "    matched_patterns = []\n",
        "\n",
        "    for pattern in self.patterns['direct_speech']:\n",
        "        if re.search(pattern, passage):\n",
        "            matched_patterns.append(pattern)\n",
        "\n",
        "    return len(matched_patterns) > 0, matched_patterns\n",
        "\n",
        "\n",
        "def calculate_molly_likelihood(self, passage: str) -> Tuple[float, List[str]]:\n",
        "    \"\"\"\n",
        "    Calculate likelihood that passage is Molly based on vocabulary markers.\n",
        "\n",
        "    This is a simple heuristic - not definitive. Think of it as a prior\n",
        "    before manual annotation. Like a really naive Bayes classifier,\n",
        "    but we're honest about its limitations. No overconfident posteriors here.\n",
        "\n",
        "    Parameters:\n",
        "        passage: The text to analyze\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (likelihood_score, list of matched markers)\n",
        "    \"\"\"\n",
        "    matched_markers = []\n",
        "    score = 0.0\n",
        "\n",
        "    # Check for distinctive Molly vocabulary\n",
        "    for pattern in self.patterns['molly_vocabulary']:\n",
        "        matches = re.findall(pattern, passage, re.IGNORECASE)\n",
        "        if matches:\n",
        "            matched_markers.append(f\"molly_vocab: {pattern}\")\n",
        "            score += 0.3 * len(matches)\n",
        "\n",
        "    # Check for female embodiment vocabulary\n",
        "    for pattern in self.patterns['female_embodiment']:\n",
        "        matches = re.findall(pattern, passage, re.IGNORECASE)\n",
        "        if matches:\n",
        "            matched_markers.append(f\"embodiment: {pattern}\")\n",
        "            score += 0.2 * len(matches)\n",
        "\n",
        "    # Check for domestic vocabulary\n",
        "    for pattern in self.patterns['domestic_vocabulary']:\n",
        "        matches = re.findall(pattern, passage, re.IGNORECASE)\n",
        "        if matches:\n",
        "            matched_markers.append(f\"domestic: {pattern}\")\n",
        "            score += 0.15 * len(matches)\n",
        "\n",
        "    # Cap at 1.0\n",
        "    return min(score, 1.0), matched_markers\n",
        "\n",
        "\n",
        "# Add methods to finder\n",
        "MollyCandidateFinder.check_mediation = check_mediation\n",
        "MollyCandidateFinder.check_direct_speech = check_direct_speech\n",
        "MollyCandidateFinder.calculate_molly_likelihood = calculate_molly_likelihood\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Method summary:\")\n",
        "print(\"- check_mediation: Identifies male-encoded memories/imagination\")\n",
        "print(\"- check_direct_speech: Identifies real-time, unmediated speech\")\n",
        "print(\"- calculate_molly_likelihood: Heuristic scoring based on vocabulary\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "9yIbkvtKZNCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Penelope episode extraction (takes the definite Molly passage)\n",
        "\n",
        "def extract_penelope(self) -> PassageCandidate:\n",
        "    \"\"\"\n",
        "    Extract the Penelope episode as a definite Molly passage.\n",
        "\n",
        "    This is the only passage we can extract with complete confidence.\n",
        "    24,000+ words of pure Molly, unmediated by any other consciousness.\n",
        "    The famous unpunctuated stream-of-consciousness monologue.\n",
        "\n",
        "    Returns:\n",
        "        PassageCandidate for the entire Penelope episode\n",
        "    \"\"\"\n",
        "    if 'Penelope' not in self.episodes:\n",
        "        raise ValueError(\"Penelope episode not found in text. Manual location required.\")\n",
        "\n",
        "    start, end = self.episodes['Penelope']\n",
        "    text = self.text[start:end]\n",
        "\n",
        "    # minimal context (before Pen)\n",
        "    context_before = self.text[max(0, start-200):start]\n",
        "\n",
        "    return PassageCandidate(\n",
        "        text=text,\n",
        "        location=start,\n",
        "        episode='Penelope',\n",
        "        passage_type=PassageType.INTERIOR_MONOLOGUE,\n",
        "        confidence=ConfidenceLevel.DEFINITE,\n",
        "        context_before=context_before,\n",
        "        context_after=\"[End of text]\",\n",
        "        flags=['penelope_episode', 'stream_of_consciousness', 'unpunctuated'],\n",
        "        reasoning=\"Penelope episode: established critical consensus as Molly's interior monologue. \"\n",
        "                  \"Pure stream-of-consciousness, unmediated by any other character's perspective.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# method for finder\n",
        "MollyCandidateFinder.extract_penelope = extract_penelope\n",
        "\n",
        "# find Pen\n",
        "print(\"=\" * 60)\n",
        "\n",
        "penelope_candidate = finder.extract_penelope()\n",
        "\n",
        "print(f\"Location: Character position {penelope_candidate.location:,}\")\n",
        "print(f\"Length: {len(penelope_candidate.text):,} characters\")\n",
        "print(f\"Approximate word count: {len(penelope_candidate.text.split()):,}\")\n",
        "print(f\"Confidence: {penelope_candidate.confidence.value}\")\n",
        "print(f\"Flags: {', '.join(penelope_candidate.flags)}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"First 500 characters of Penelope:\")\n",
        "print(\"-\" * 60)\n",
        "print(penelope_candidate.text[:500])\n",
        "print(\"-\" * 60)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"Last 500 characters of Penelope:\")\n",
        "print(\"-\" * 60)\n",
        "print(penelope_candidate.text[-500:])\n",
        "print(\"-\" * 60)"
      ],
      "metadata": {
        "id": "8zXClc5_Zlai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialogue Candidate Extraction (flag potential Molly dialogue for manual review)\n",
        "\n",
        "def find_dialogue_candidates(self, max_candidates: int = 100) -> List[PassageCandidate]:\n",
        "    \"\"\"\n",
        "    Find potential Molly dialogue throughout Ulysses.\n",
        "\n",
        "    This method identifies passages that MIGHT be Molly speaking,\n",
        "    but flags them appropriately for human review based on mediation markers.\n",
        "\n",
        "    The challenge: Joyce doesn't always cleanly mark speakers, and we must\n",
        "    distinguish between Molly speaking vs. Bloom remembering her words.\n",
        "\n",
        "    Parameters:\n",
        "        max_candidates: Maximum number of candidates to extract (prevents overflow)\n",
        "\n",
        "    Returns:\n",
        "        List of PassageCandidate objects for manual review\n",
        "    \"\"\"\n",
        "    candidates = []\n",
        "\n",
        "    # dialogue attribution patterns (conservative approach)\n",
        "    dialogue_patterns = [\n",
        "        r'(?:Molly|Mrs\\s+Bloom)\\s+said[:\\.]?\\s*[—\"\\']([^\"\\'—]{10,300})[\"\\']?',\n",
        "        r'—\\s*([^—\\n]{20,300})\\s*(?:Molly|she)\\s+said',\n",
        "        r'she\\s+said[:\\.]?\\s*[—\"\\']([^\"\\'—]{10,300})[\"\\']?',\n",
        "    ]\n",
        "\n",
        "    for pattern in dialogue_patterns:\n",
        "        matches = list(re.finditer(pattern, self.text, re.IGNORECASE))\n",
        "\n",
        "        print(f\"Pattern '{pattern[:50]}...' found {len(matches)} matches\")\n",
        "\n",
        "        for match in matches[:max_candidates]:  # lim to prevent overflow\n",
        "            location = match.start()\n",
        "            passage = match.group(0)\n",
        "\n",
        "            # skip if in pen\n",
        "            if 'Penelope' in self.episodes:\n",
        "                pen_start, pen_end = self.episodes['Penelope']\n",
        "                if pen_start <= location < pen_end:\n",
        "                    continue\n",
        "\n",
        "            # context\n",
        "            ctx_before, ctx_after = self.get_context(location)\n",
        "\n",
        "            # mediation\n",
        "            is_mediated, mediation_patterns = self.check_mediation(passage, ctx_before)\n",
        "            is_direct, direct_patterns = self.check_direct_speech(passage)\n",
        "\n",
        "            # calc Molly likelihood based on vocabulary\n",
        "            molly_score, vocab_markers = self.calculate_molly_likelihood(passage)\n",
        "\n",
        "            # determine confidence based on checks\n",
        "            flags = []\n",
        "\n",
        "            if is_mediated:\n",
        "                confidence = ConfidenceLevel.EXCLUDE\n",
        "                flags.extend(['mediated_speech'] + [f\"mediation: {p[:30]}\" for p in mediation_patterns[:2]])\n",
        "                reasoning = \"Contains mediation markers - likely Bloom's encoding of her words. \" \\\n",
        "                           \"Male-mediated memory, not primary source.\"\n",
        "            elif is_direct and molly_score > 0.3:\n",
        "                confidence = ConfidenceLevel.PROBABLE\n",
        "                flags.extend(['direct_speech'] + vocab_markers[:3])\n",
        "                reasoning = f\"Direct speech markers present with Molly vocabulary (score: {molly_score:.2f}). \" \\\n",
        "                           \"Likely real-time dialogue, but requires verification.\"\n",
        "            elif is_direct:\n",
        "                confidence = ConfidenceLevel.REQUIRES_REVIEW\n",
        "                flags.append('direct_speech_low_confidence')\n",
        "                reasoning = \"Direct speech markers present, but limited Molly-specific vocabulary. \" \\\n",
        "                           \"Could be another female character. Requires close reading.\"\n",
        "            else:\n",
        "                confidence = ConfidenceLevel.REQUIRES_REVIEW\n",
        "                flags.append('ambiguous_attribution')\n",
        "                reasoning = \"Unclear attribution and no strong markers. Requires close reading for context.\"\n",
        "\n",
        "            candidates.append(PassageCandidate(\n",
        "                text=passage,\n",
        "                location=location,\n",
        "                episode=self.get_episode_name(location),\n",
        "                passage_type=PassageType.DIRECT_DIALOGUE,\n",
        "                confidence=confidence,\n",
        "                context_before=ctx_before,\n",
        "                context_after=ctx_after,\n",
        "                flags=flags,\n",
        "                reasoning=reasoning\n",
        "            ))\n",
        "\n",
        "    return candidates\n",
        "\n",
        "\n",
        "# method for finder\n",
        "MollyCandidateFinder.find_dialogue_candidates = find_dialogue_candidates\n",
        "\n",
        "# dialogue candidates\n",
        "print(\"Extracting dialogue candidates...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "dialogue_candidates = finder.find_dialogue_candidates(max_candidates=100)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"Total dialogue candidates found: {len(dialogue_candidates)}\")\n",
        "\n",
        "# summary by confidence level\n",
        "confidence_summary = {}\n",
        "for candidate in dialogue_candidates:\n",
        "    conf = candidate.confidence.value\n",
        "    confidence_summary[conf] = confidence_summary.get(conf, 0) + 1\n",
        "\n",
        "print(\"\\nBreakdown by confidence level:\")\n",
        "for conf, count in sorted(confidence_summary.items()):\n",
        "    print(f\"  {conf}: {count}\")\n",
        "\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "e1D_5OpBaagy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Candidate Review (sample candidates from each confidence category for manual review)\n",
        "\n",
        "def display_candidate_sample(candidates: List[PassageCandidate],\n",
        "                            confidence_level: ConfidenceLevel,\n",
        "                            n_samples: int = 3):\n",
        "    \"\"\"\n",
        "    Display sample candidates for a given confidence level.\n",
        "\n",
        "    Parameters:\n",
        "        candidates: List of all candidates\n",
        "        confidence_level: Which confidence level to display\n",
        "        n_samples: Number of samples to show\n",
        "    \"\"\"\n",
        "    filtered = [c for c in candidates if c.confidence == confidence_level]\n",
        "\n",
        "    if not filtered:\n",
        "        print(f\"No candidates found for confidence level: {confidence_level.value}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"CONFIDENCE LEVEL: {confidence_level.value.upper()}\")\n",
        "    print(f\"Total candidates: {len(filtered)}\")\n",
        "    print(f\"Showing {min(n_samples, len(filtered))} samples\")\n",
        "    print('=' * 60)\n",
        "\n",
        "    for i, candidate in enumerate(filtered[:n_samples], 1):\n",
        "        print(f\"\\n{'-' * 60}\")\n",
        "        print(f\"Sample {i}/{min(n_samples, len(filtered))}\")\n",
        "        print(f\"{'-' * 60}\")\n",
        "        print(f\"Location: Position {candidate.location:,}\")\n",
        "        print(f\"Episode: {candidate.episode or 'Unknown'}\")\n",
        "        print(f\"Type: {candidate.passage_type.value}\")\n",
        "        print(f\"\\nReasoning: {candidate.reasoning}\")\n",
        "        print(f\"\\nFlags: {', '.join(candidate.flags[:5])}\")\n",
        "\n",
        "        print(f\"\\nContext (before, last 100 chars):\")\n",
        "        print(f\"...{candidate.context_before[-100:]}\")\n",
        "\n",
        "        print(f\"\\nPassage (first 300 chars):\")\n",
        "        print(candidate.text[:300] + ('...' if len(candidate.text) > 300 else ''))\n",
        "\n",
        "        print(f\"\\nContext (after, first 100 chars):\")\n",
        "        print(f\"{candidate.context_after[:100]}...\")\n",
        "\n",
        "\n",
        "# samples from each confidence category\n",
        "print(\"Displaying sample candidates for manual inspection...\")\n",
        "\n",
        "# candidates (if any outside Penelope)\n",
        "display_candidate_sample(dialogue_candidates, ConfidenceLevel.DEFINITE, n_samples=2)\n",
        "\n",
        "# other candidates\n",
        "display_candidate_sample(dialogue_candidates, ConfidenceLevel.PROBABLE, n_samples=3)\n",
        "\n",
        "# review candidates\n",
        "display_candidate_sample(dialogue_candidates, ConfidenceLevel.REQUIRES_REVIEW, n_samples=3)\n",
        "\n",
        "# excluded candidates (indicated flag)\n",
        "display_candidate_sample(dialogue_candidates, ConfidenceLevel.EXCLUDE, n_samples=3)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Sample review complete.\")\n",
        "print(\"These samples illustrate the kinds of decisions required in manual annotation.\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "EqfM2G61bMi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# markdown report generation\n",
        "\n",
        "def generate_header() -> str:\n",
        "    \"\"\"Generate markdown header for annotation file.\"\"\"\n",
        "    return \"\"\"# Molly Bloom Text Extraction: Manual Annotation\n",
        "\n",
        "## Purpose\n",
        "\n",
        "This document presents candidate passages for inclusion in the Molly Bloom corpus.\n",
        "Automatic classification has been applied, but all passages require human judgment\n",
        "due to the complex attribution challenges in Joyce's text.\n",
        "\n",
        "## Decision Framework\n",
        "\n",
        "For each passage, determine:\n",
        "\n",
        "### 1. Attribution\n",
        "Is this definitively Molly's voice?\n",
        "\n",
        "**Exclude:**\n",
        "- Passages mediated through Bloom's memory or imagination\n",
        "- Reported speech or paraphrased content\n",
        "- Male-encoded translations of her words\n",
        "\n",
        "**Include:**\n",
        "- Direct speech in real-time narrative moments\n",
        "- Unmediated interior monologue\n",
        "- Theatrical/performed speech (flagged for Stage 2)\n",
        "\n",
        "### 2. Stage Assignment\n",
        "If included, which training stage?\n",
        "\n",
        "- **Stage 1**: Vocabulary foundation (all Molly text, used for frequency analysis)\n",
        "- **Stage 2**: Public voice (dialogue, theatrical, conversational register)\n",
        "- **Stage 3**: Interior consciousness (stream-of-consciousness, unpunctuated flow)\n",
        "\n",
        "### 3. Notes\n",
        "Record reasoning for ambiguous cases, especially:\n",
        "- Free indirect discourse boundaries\n",
        "- Circe episode theatrical passages\n",
        "- Passages where attribution is unclear\n",
        "\n",
        "## Annotation Format\n",
        "\n",
        "For each passage, mark:\n",
        "- **Decision**: INCLUDE / EXCLUDE / UNCERTAIN\n",
        "- **Stage**: 1 / 2 / 3 / N/A\n",
        "- **Notes**: Your reasoning\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_penelope_section(penelope: PassageCandidate) -> str:\n",
        "    \"\"\"Generate section for Penelope episode.\"\"\"\n",
        "    word_count = len(penelope.text.split())\n",
        "\n",
        "    return f\"\"\"## Section 1: Penelope Episode (Definite Inclusion)\n",
        "\n",
        "**Status**: DEFINITE INCLUSION\n",
        "**Recommended Stage**: 3 (Interior Consciousness)\n",
        "**Location**: Character position {penelope.location:,}\n",
        "**Length**: {len(penelope.text):,} characters (~{word_count:,} words)\n",
        "\n",
        "**Reasoning**: {penelope.reasoning}\n",
        "\n",
        "**Flags**: {', '.join(penelope.flags)}\n",
        "\n",
        "### First 1000 characters:\n",
        "```\n",
        "{penelope.text[:1000]}\n",
        "```\n",
        "\n",
        "### Last 500 characters:\n",
        "```\n",
        "{penelope.text[-500:]}\n",
        "```\n",
        "\n",
        "**Decision**: INCLUDE\n",
        "**Stage**: 3\n",
        "**Notes**:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def format_flags(flags: List[str]) -> str:\n",
        "    \"\"\"Format flags as markdown list.\"\"\"\n",
        "    if not flags:\n",
        "        return \"- None\"\n",
        "    return \"\\n\".join(f\"- `{flag}`\" for flag in flags)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Functions available:\")\n",
        "print(\"- generate_header(): Creates annotation file header with instructions\")\n",
        "print(\"- generate_penelope_section(): Formats Penelope episode entry\")\n",
        "print(\"- format_flags(): Formats flag lists for display\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "sESYftQnbpko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# markdown report generation / candidate sections\n",
        "\n",
        "def generate_candidate_section(section_title: str,\n",
        "                               candidates: List[PassageCandidate],\n",
        "                               section_number: int) -> str:\n",
        "    \"\"\"\n",
        "    Generate section for a group of candidates.\n",
        "\n",
        "    Parameters:\n",
        "        section_title: Title for this confidence category\n",
        "        candidates: List of candidates to include\n",
        "        section_number: Section number for organization\n",
        "\n",
        "    Returns:\n",
        "        Formatted markdown string\n",
        "    \"\"\"\n",
        "    section = f\"\"\"## Section {section_number}: {section_title} ({len(candidates)} passages)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    if not candidates:\n",
        "        section += \"*No candidates in this category.*\\n\\n---\\n\\n\"\n",
        "        return section\n",
        "\n",
        "    for i, candidate in enumerate(candidates, 1):\n",
        "        # truncate passage for display\n",
        "        passage_display = candidate.text[:500]\n",
        "        if len(candidate.text) > 500:\n",
        "            passage_display += \"\\n[... passage continues ...]\"\n",
        "\n",
        "        section += f\"\"\"### Passage {section_number}.{i:03d}\n",
        "\n",
        "**Location**: Position {candidate.location:,}\n",
        "**Episode**: {candidate.episode or \"Unknown\"}\n",
        "**Type**: {candidate.passage_type.value}\n",
        "**Automatic Confidence**: {candidate.confidence.value}\n",
        "\n",
        "**Reasoning**: {candidate.reasoning}\n",
        "\n",
        "**Automatic Flags**:\n",
        "{format_flags(candidate.flags)}\n",
        "\n",
        "**Context (preceding 150 characters)**:\n",
        "```\n",
        "...{candidate.context_before[-150:]}\n",
        "```\n",
        "\n",
        "**Passage**:\n",
        "```\n",
        "{passage_display}\n",
        "```\n",
        "\n",
        "**Context (following 150 characters)**:\n",
        "```\n",
        "{candidate.context_after[:150]}...\n",
        "```\n",
        "\n",
        "**Decision**: [ INCLUDE / EXCLUDE / UNCERTAIN ]\n",
        "**Stage**: [ 1 / 2 / 3 / N/A ]\n",
        "**Notes**:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    return section\n",
        "\n",
        "\n",
        "def generate_statistics_section(dialogue_candidates: List[PassageCandidate],\n",
        "                               penelope: PassageCandidate) -> str:\n",
        "    \"\"\"Generate summary statistics section.\"\"\"\n",
        "\n",
        "    total_candidates = len(dialogue_candidates) + 1  # +1 for Pen\n",
        "\n",
        "    # count by confidence\n",
        "    confidence_counts = {}\n",
        "    for candidate in dialogue_candidates:\n",
        "        conf = candidate.confidence.value\n",
        "        confidence_counts[conf] = confidence_counts.get(conf, 0) + 1\n",
        "\n",
        "    # count by episode\n",
        "    episode_counts = {}\n",
        "    for candidate in dialogue_candidates:\n",
        "        ep = candidate.episode or \"Unknown\"\n",
        "        episode_counts[ep] = episode_counts.get(ep, 0) + 1\n",
        "\n",
        "    stats = f\"\"\"## Extraction Statistics\n",
        "\n",
        "**Total candidates identified**: {total_candidates}\n",
        "\n",
        "### By Confidence Level:\n",
        "- Definite: {confidence_counts.get('definite', 0) + 1} (including Penelope)\n",
        "- Probable: {confidence_counts.get('probable', 0)}\n",
        "- Requires Review: {confidence_counts.get('requires_review', 0)}\n",
        "- Flagged for Exclusion: {confidence_counts.get('exclude', 0)}\n",
        "\n",
        "### By Episode:\n",
        "\"\"\"\n",
        "\n",
        "    for episode, count in sorted(episode_counts.items()):\n",
        "        stats += f\"- {episode}: {count}\\n\"\n",
        "\n",
        "    stats += f\"- Penelope: 1 (complete episode)\\n\"\n",
        "\n",
        "    stats += \"\"\"\n",
        "### Penelope Statistics:\n",
        "- Character count: {:,}\n",
        "- Approximate word count: {:,}\n",
        "- Status: Definite inclusion (Stage 3)\n",
        "\n",
        "---\n",
        "\n",
        "\"\"\".format(len(penelope.text), len(penelope.text.split()))\n",
        "\n",
        "    return stats\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Functions available:\")\n",
        "print(\"- generate_candidate_section(): Formats groups of candidates\")\n",
        "print(\"- generate_statistics_section(): Creates summary statistics\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "2QTEHLTqb0wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# complete annotation report generation\n",
        "\n",
        "def generate_complete_annotation_report(penelope: PassageCandidate,\n",
        "                                       dialogue_candidates: List[PassageCandidate],\n",
        "                                       output_filename: str = 'molly_candidates_annotation.md'):\n",
        "    \"\"\"\n",
        "    Generate complete annotation report combining all sections.\n",
        "\n",
        "    Parameters:\n",
        "        penelope: The Penelope episode candidate\n",
        "        dialogue_candidates: All dialogue candidates\n",
        "        output_filename: Name for output file\n",
        "\n",
        "    Returns:\n",
        "        Path to generated file\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Generating complete annotation report...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # sort candidates by confidence level\n",
        "    definite = [c for c in dialogue_candidates if c.confidence == ConfidenceLevel.DEFINITE]\n",
        "    probable = [c for c in dialogue_candidates if c.confidence == ConfidenceLevel.PROBABLE]\n",
        "    review = [c for c in dialogue_candidates if c.confidence == ConfidenceLevel.REQUIRES_REVIEW]\n",
        "    exclude = [c for c in dialogue_candidates if c.confidence == ConfidenceLevel.EXCLUDE]\n",
        "\n",
        "    print(f\"Organizing {len(dialogue_candidates)} dialogue candidates:\")\n",
        "    print(f\"  Definite: {len(definite)}\")\n",
        "    print(f\"  Probable: {len(probable)}\")\n",
        "    print(f\"  Requires Review: {len(review)}\")\n",
        "    print(f\"  Flagged for Exclusion: {len(exclude)}\")\n",
        "\n",
        "    # assemble complete report\n",
        "    report_sections = []\n",
        "\n",
        "    # header with instructions\n",
        "    report_sections.append(generate_header())\n",
        "\n",
        "    # statistics summary\n",
        "    report_sections.append(generate_statistics_section(dialogue_candidates, penelope))\n",
        "\n",
        "    # Pen (definite)\n",
        "    report_sections.append(generate_penelope_section(penelope))\n",
        "\n",
        "    # definite dialogue candidates\n",
        "    if definite:\n",
        "        report_sections.append(generate_candidate_section(\n",
        "            \"Definite Dialogue Candidates\", definite, 2\n",
        "        ))\n",
        "\n",
        "    # probable candidates\n",
        "    if probable:\n",
        "        report_sections.append(generate_candidate_section(\n",
        "            \"Probable Candidates (Verification Required)\", probable, 3\n",
        "        ))\n",
        "\n",
        "    # requires review\n",
        "    if review:\n",
        "        report_sections.append(generate_candidate_section(\n",
        "            \"Ambiguous Candidates (Close Reading Required)\", review, 4\n",
        "        ))\n",
        "\n",
        "    # excluded (showing reasoning)\n",
        "    if exclude:\n",
        "        report_sections.append(generate_candidate_section(\n",
        "            \"Flagged for Exclusion (Male-Mediated or Non-Molly)\", exclude, 5\n",
        "        ))\n",
        "\n",
        "    # footer\n",
        "    report_sections.append(\"\"\"\n",
        "## Next Steps\n",
        "\n",
        "1. Review each passage in context\n",
        "2. Make inclusion/exclusion decisions\n",
        "3. Assign stage numbers for included passages\n",
        "4. Document reasoning for ambiguous cases\n",
        "5. Use annotations to generate final corpus files\n",
        "\n",
        "## Notes on Ambiguous Cases\n",
        "\n",
        "Record patterns you notice during annotation:\n",
        "- Common mediation structures not caught by automatic detection\n",
        "- Distinctive Molly vocabulary to add to patterns\n",
        "- Episode-specific attribution challenges\n",
        "- Free indirect discourse boundaries\n",
        "\n",
        "---\n",
        "\n",
        "*Report generated by MollyCandidateFinder*\n",
        "*Project: yes-i-said-yes-i-will-yes*\n",
        "*For Molly.*\n",
        "\"\"\")\n",
        "\n",
        "    # write\n",
        "    complete_report = \"\".join(report_sections)\n",
        "\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(complete_report)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"Annotation report generated successfully!\")\n",
        "    print(f\"Filename: {output_filename}\")\n",
        "    print(f\"Size: {len(complete_report):,} characters\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return output_filename\n",
        "\n",
        "\n",
        "# complete report\n",
        "output_file = generate_complete_annotation_report(\n",
        "    penelope=penelope_candidate,\n",
        "    dialogue_candidates=dialogue_candidates,\n",
        "    output_filename='molly_candidates_annotation.md'\n",
        ")"
      ],
      "metadata": {
        "id": "piSb9EtYcaQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Preparing annotation file for download...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# get file\n",
        "files.download(output_file)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ANNOTATION FILE DOWNLOADED\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Open the markdown file in your preferred editor\")\n",
        "print(\"2. Review each candidate passage carefully\")\n",
        "print(\"3. Make INCLUDE/EXCLUDE/UNCERTAIN decisions\")\n",
        "print(\"4. Assign training stages (1, 2, or 3) for included passages\")\n",
        "print(\"5. Document your reasoning for ambiguous cases\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Key considerations during annotation:\")\n",
        "print(\"- Bloom's memories of Molly's words are male-encoded (EXCLUDE)\")\n",
        "print(\"- Direct speech in real-time scenes is primary source (INCLUDE)\")\n",
        "print(\"- Free indirect discourse requires close reading\")\n",
        "print(\"- Circe theatrical passages need special attention\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nRemember: This is computational feminism.\")\n",
        "print(\"We're building a corpus where female interiority is foundational,\")\n",
        "print(\"not filtered through male consciousness.\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "XFjYeJvJc8Ej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}